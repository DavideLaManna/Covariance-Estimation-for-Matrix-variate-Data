---
title: "DiagLDA"
author: "Davide La Manna"
date: "2023-05-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Diag LDA

In this brief report we will show the results of classification using LDA with a diagonal covariance matrix.  We will include the code used for clarity.

```{r}
library(abind) #for concatenate the data
library(caret) #for confusion matrix
source("~/Desktop/semester project/SemesterProject/functions/LDA.R")
#load the data
data<-get(load("./MFCCs.RData"))

# random seed for the reproducibility 
set.seed(123)
#prepare the data
alpha<-0.8
i<-1
train_set<-NULL
test_set<-NULL
test_labels<-NULL
attr <- (attributes(data))$names
n<-dim(data$yes)[2]
m<-dim(data$yes)[3]
mean<- array(NA, dim=c(n, m, length(attr)))
#create test set and train set array, mean array
for (name in attr) {
  val<-partition(data[[name]],alpha)
  train_set<-abind(train_set,val$train,along=1)
  test_set<-abind(test_set,val$test,along=1)
  test_labels<-factor(c(test_labels,rep(i,dim(val$test)[1])),level=c(1:10))
  mean[,,i]<-apply(val$train, c(2,3), mean)
  i<-i+1
}

A<-rep(0,n*m)
for(i in 1:1287){
  A[i]<-var(matrix(train_set,ncol=n*m)[,i])
  }
#we transform the matrix into an array just to make the data congruent with our own classification algorithm
B<-array(diag(A),c(n,m,n,m))
#solve inverse problem for LDA 
w<-array(NA,dim=c(dim(mean)[1],dim(mean)[2],length(attr)))
for (i in 1:dim(mean)[2]) {
  for(j in 1:dim(mean)[3])
    w[,i,j]=solve(B[,i,,i],mean[,i,j])}
#predict the value
predictions<-my_lda(test_set,mean,w)

# Plot the confusion matrix
cm <- as.matrix(confusionMatrix(factor(predictions,level=c(1:10)), test_labels)$table)
cm_melted <- melt(cm)
colnames(cm_melted) <- c("True", "Predicted", "value")
ggplot(data = cm_melted, aes(x = True, y = Predicted, fill = value)) +
  geom_tile() +
  geom_text(aes(label = value), color = "black", size = 4) +
  scale_fill_gradient(low = "white", high = "blue") +
  scale_x_discrete(labels = attr,limits=attr) + 
  scale_y_discrete(labels = attr,limits=attr) +
  theme_minimal() +
  theme(text = element_text(size = 14)) +
  labs(title = "Confusion Matrix diag LDA", x = "True", y = "Predicted")

# Calculate the accuracy of the algorithm
accuracy <- sum(diag(confusionMatrix(factor(predictions,level=c(1:10)), test_labels)$table)) / length(test_labels)
cat("Accuracy:", accuracy * 100, "%\n")
```
Let us show for curiosity the values of the vector A
```{r}
plot(A)
```

We think such a high level of accuracy is related to the dimensionality of the problem. From the plot of the covariance matrix (found, for example, in the exploratory analysis), we can see that the richness of the covariance matrix of the data is located in a neighborhood of the diagonal, so our assumption turns out to be reasonable.